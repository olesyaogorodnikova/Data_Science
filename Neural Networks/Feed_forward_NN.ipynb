{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5PKsj4BPZz32"
   },
   "source": [
    "# Day 1&2: Feed forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ByCThFjJP7gQ"
   },
   "source": [
    "## Feed Forward NN for Structured Data\n",
    "\n",
    "### Sources:\n",
    "Inspired by https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "\n",
    "### Description:\n",
    "You are provided with a data set of almost 100,000 job ads from a job platform. In order to make their services more attractive they want to introduce a new feature which predicts the expected number of views for a new job ad based on the job title and a few other features. This will help their customers to create job titels that attract more views.\n",
    "\n",
    "Some of our students have already vectorized the job titles. (Word embeddings generated by Google's BERT NLP model have been created and provided. Next week you will learn how to do this yourself!) In addition, you have some metadata and some general features of the job titles (e.g. all letters capitalized, ...).\n",
    "\n",
    "Since there are several hundreds of features, using a neural network seems to be the most promising approach.\n",
    "\n",
    "## Exercise 2: Regression\n",
    "Using the same data set as in exercise 1 we now would like to predict directly the expected number of views within 10 days. This time it is a regression problem, which means, that besides prepering a new target vector, you have to adjust the layers of our NN - especially the output layer.\n",
    "\n",
    "Furthermore, you have to choose an adequate loss function and set the correct metric for the early stopping condition.\n",
    "\n",
    "Apply your model on the provided features of the test set. You can upload your predictions on Kaggle and compete with your class mates. :)\n",
    "\n",
    "\n",
    "### Some advices:\n",
    "  * Define a MSE loss function\n",
    "  * Scale your data properly\n",
    "  * Adjust the output activation function\n",
    "\n",
    "\n",
    "### Bonus: \n",
    "\n",
    "  * Play with Tensorboard for tracking and visualizing the training and performance of your models. https://www.tensorflow.org/tensorboard/get_started \n",
    "\n",
    "  * Use Tensorboard for tracking and optimizing hyperparameters. Follow this tutorial: https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams\n",
    "\n",
    "  * Try to provoke overfitting and underfitting. Check this tutorial: https://www.tensorflow.org/tutorials/keras/overfit_and_underfit\n",
    "\n",
    "  * Compare your results with some other models that you learnt in the machine learning module\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qR3QWVKBcLoE"
   },
   "source": [
    "# Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mg5TjApVbuZv"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3176,
     "status": "ok",
     "timestamp": 1577157466961,
     "user": {
      "displayName": "Badrudin Stanicki",
      "photoUrl": "",
      "userId": "13526963153831051460"
     },
     "user_tz": -60
    },
    "id": "fYBlUQ5FvzxP",
    "outputId": "0f146ead-d0c9-4a67-8b7a-6553e2dcd5f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "izjjYrLswXS0"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# import tensorflow_addons as tfa\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PowerTransformer\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "import yaml\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LjcZIC6t58Cq"
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (20, 12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kx-CHFrLweUa"
   },
   "source": [
    "## Load data and functions\n",
    "Connect to Google Drive. Code snippets for this and other frequently required operations can be found in the `Code snippets` tab of Google Colab.\n",
    "\n",
    "You have to authorizate Google Colab to access your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4606,
     "status": "ok",
     "timestamp": 1577157468436,
     "user": {
      "displayName": "Badrudin Stanicki",
      "photoUrl": "",
      "userId": "13526963153831051460"
     },
     "user_tz": -60
    },
    "id": "fCrFz7p8cqN2",
    "outputId": "91dad49b-e994-46f2-ed7c-3e4fe205ba1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Da3CSaiFx5ec"
   },
   "source": [
    "### Set working directory\n",
    "You need to change this to the directory where you have saved this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4596,
     "status": "ok",
     "timestamp": 1577157468445,
     "user": {
      "displayName": "Badrudin Stanicki",
      "photoUrl": "",
      "userId": "13526963153831051460"
     },
     "user_tz": -60
    },
    "id": "dx7sY75LQdFW",
    "outputId": "f283db78-dbd9-4cde-99e9-08501d3ee3ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gdrive/My Drive/Propulsion Academy/03_Bootcamps/Data Science/Teaching Material/NN & CNN/dev/week-7-exercises/Day1+2_feed_forward_NN\n"
     ]
    }
   ],
   "source": [
    "# You have to set your own location!\n",
    "project_dir = \"/gdrive/My Drive/Propulsion Academy/03_Bootcamps/Data Science/Teaching Material/NN & CNN/dev/week-7-exercises/Day1+2_feed_forward_NN\"\n",
    "%cd {project_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "alvTAaMNxx3Y"
   },
   "source": [
    "### Import custom functions\n",
    "We import some additional functions that are provided in the `functions` directory. Use the same kind of structure to import your own functions.\n",
    "\n",
    "In order to be able to load `.py` files from the functions folder we first have to add its location to the `sys.path` variable. \n",
    "\n",
    "To be sure that the correct function is loaded we insert its location at the very begining of `sys.path`. https://stackoverflow.com/questions/31291608/effect-of-using-sys-path-insert0-path-and-sys-pathappend-when-loading-modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-9Rq0ULxvfs"
   },
   "outputs": [],
   "source": [
    "# Add the corresponding Google Drive folder to sys.path\n",
    "sys.path.insert(0, os.path.join(project_dir, 'functions'))\n",
    "\n",
    "# import functions\n",
    "import tf_metrics\n",
    "import evaluate_results\n",
    "import data_loader\n",
    "import nn_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uyfWK0lOyRTR"
   },
   "source": [
    "### Load configuration file\n",
    "All required paths for loading the data and additional parameters on how to pre-process it are saved in a configuration file. We use a YAML file.\n",
    "YAML as a human friendly data serialization standard. You can see it as a more beautiful version of JSON.\n",
    "\n",
    "It is compatible with all relevant programming languages.\n",
    "\n",
    "Have a look at the file which is in the `configuration` directory. Add your own parameters which are required for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4571,
     "status": "ok",
     "timestamp": 1577157468450,
     "user": {
      "displayName": "Badrudin Stanicki",
      "photoUrl": "",
      "userId": "13526963153831051460"
     },
     "user_tz": -60
    },
    "id": "GL307fiSpKaD",
    "outputId": "0bdeafd6-5462-474a-a2e2-850d5d538630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:\n",
      "  categorical: [month, package_id, industry_name, city]\n",
      "  numerical: [contract_pct_from, contract_pct_to, title_num_words]\n",
      "  passthrough: [title_aggressive, title_female, title_percent, title_location, title_diploma,\n",
      "    title_chief, title_prob_en, title_prob_de, title_prob_fr]\n",
      "paths: {features_test: ./data/jobs_features_test.csv, features_train: ./data/jobs_features_train.csv,\n",
      "  target_train: ./data/jobs_10dviews_train.csv}\n",
      "target:\n",
      "  bins: [0, 10000, 20000, 50000, 100000, 200000, .inf]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_file_path = \"./configuration/config_file.yml\"\n",
    "config = yaml.safe_load(open(config_file_path))\n",
    "print(yaml.dump(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VQDcW2WPyYGB"
   },
   "source": [
    "### Load the data set from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "inTflQ9XQJx9"
   },
   "outputs": [],
   "source": [
    "# load training data\n",
    "X_train_raw, y_train_raw, X_test_raw = data_loader.load_data(project_dir, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sln9I-PgycyP"
   },
   "source": [
    "### Inspect the loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24980,
     "status": "ok",
     "timestamp": 1577157488915,
     "user": {
      "displayName": "Badrudin Stanicki",
      "photoUrl": "",
      "userId": "13526963153831051460"
     },
     "user_tz": -60
    },
    "id": "bJO1j7zIzU36",
    "outputId": "83022bd5-4202-4dd5-e166-89f171281879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data is  (81388, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contract_pct_from</th>\n",
       "      <th>contract_pct_to</th>\n",
       "      <th>title_num_words</th>\n",
       "      <th>title_aggressive</th>\n",
       "      <th>title_female</th>\n",
       "      <th>title_percent</th>\n",
       "      <th>title_location</th>\n",
       "      <th>title_diploma</th>\n",
       "      <th>title_chief</th>\n",
       "      <th>title_prob_en</th>\n",
       "      <th>title_prob_de</th>\n",
       "      <th>title_prob_fr</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>...</th>\n",
       "      <th>728</th>\n",
       "      <th>729</th>\n",
       "      <th>730</th>\n",
       "      <th>731</th>\n",
       "      <th>732</th>\n",
       "      <th>733</th>\n",
       "      <th>734</th>\n",
       "      <th>735</th>\n",
       "      <th>736</th>\n",
       "      <th>737</th>\n",
       "      <th>738</th>\n",
       "      <th>739</th>\n",
       "      <th>740</th>\n",
       "      <th>741</th>\n",
       "      <th>742</th>\n",
       "      <th>743</th>\n",
       "      <th>744</th>\n",
       "      <th>745</th>\n",
       "      <th>746</th>\n",
       "      <th>747</th>\n",
       "      <th>748</th>\n",
       "      <th>749</th>\n",
       "      <th>750</th>\n",
       "      <th>751</th>\n",
       "      <th>752</th>\n",
       "      <th>753</th>\n",
       "      <th>754</th>\n",
       "      <th>755</th>\n",
       "      <th>756</th>\n",
       "      <th>757</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "      <td>81388.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.633275</td>\n",
       "      <td>96.474714</td>\n",
       "      <td>4.665258</td>\n",
       "      <td>0.039121</td>\n",
       "      <td>0.521404</td>\n",
       "      <td>0.382046</td>\n",
       "      <td>0.011709</td>\n",
       "      <td>0.040116</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.189532</td>\n",
       "      <td>0.680005</td>\n",
       "      <td>0.024746</td>\n",
       "      <td>-0.262695</td>\n",
       "      <td>-0.081360</td>\n",
       "      <td>0.059723</td>\n",
       "      <td>-0.276611</td>\n",
       "      <td>0.351807</td>\n",
       "      <td>0.007587</td>\n",
       "      <td>0.328369</td>\n",
       "      <td>0.139038</td>\n",
       "      <td>-0.160400</td>\n",
       "      <td>-0.341064</td>\n",
       "      <td>-0.050812</td>\n",
       "      <td>-0.291748</td>\n",
       "      <td>0.278809</td>\n",
       "      <td>0.316406</td>\n",
       "      <td>-0.272705</td>\n",
       "      <td>0.344238</td>\n",
       "      <td>-0.072571</td>\n",
       "      <td>-0.161621</td>\n",
       "      <td>-0.092773</td>\n",
       "      <td>0.053772</td>\n",
       "      <td>-0.331787</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>-0.080933</td>\n",
       "      <td>0.365234</td>\n",
       "      <td>0.340576</td>\n",
       "      <td>-0.063049</td>\n",
       "      <td>0.050629</td>\n",
       "      <td>-0.072266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003885</td>\n",
       "      <td>-0.293945</td>\n",
       "      <td>0.072388</td>\n",
       "      <td>0.055054</td>\n",
       "      <td>-0.033813</td>\n",
       "      <td>0.152222</td>\n",
       "      <td>-0.246582</td>\n",
       "      <td>0.166382</td>\n",
       "      <td>-0.006775</td>\n",
       "      <td>0.214233</td>\n",
       "      <td>-0.220825</td>\n",
       "      <td>0.422363</td>\n",
       "      <td>-0.042908</td>\n",
       "      <td>0.309570</td>\n",
       "      <td>-0.350098</td>\n",
       "      <td>0.110107</td>\n",
       "      <td>-0.193115</td>\n",
       "      <td>0.065125</td>\n",
       "      <td>-0.257812</td>\n",
       "      <td>-0.136719</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>-0.131714</td>\n",
       "      <td>0.343506</td>\n",
       "      <td>-0.175781</td>\n",
       "      <td>-0.022964</td>\n",
       "      <td>-0.224365</td>\n",
       "      <td>-0.162109</td>\n",
       "      <td>-0.201538</td>\n",
       "      <td>-0.316895</td>\n",
       "      <td>-0.232178</td>\n",
       "      <td>0.430176</td>\n",
       "      <td>-0.403320</td>\n",
       "      <td>0.229614</td>\n",
       "      <td>-0.223511</td>\n",
       "      <td>-0.050659</td>\n",
       "      <td>-0.060547</td>\n",
       "      <td>-0.195557</td>\n",
       "      <td>-0.345459</td>\n",
       "      <td>-0.012093</td>\n",
       "      <td>-0.167358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.179258</td>\n",
       "      <td>12.141145</td>\n",
       "      <td>2.481178</td>\n",
       "      <td>0.193885</td>\n",
       "      <td>0.499545</td>\n",
       "      <td>0.485891</td>\n",
       "      <td>0.107575</td>\n",
       "      <td>0.196234</td>\n",
       "      <td>0.045387</td>\n",
       "      <td>0.370144</td>\n",
       "      <td>0.441872</td>\n",
       "      <td>0.146484</td>\n",
       "      <td>0.293457</td>\n",
       "      <td>0.249023</td>\n",
       "      <td>0.261230</td>\n",
       "      <td>0.258057</td>\n",
       "      <td>0.263672</td>\n",
       "      <td>0.221069</td>\n",
       "      <td>0.359131</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.262207</td>\n",
       "      <td>0.220581</td>\n",
       "      <td>0.196045</td>\n",
       "      <td>0.310059</td>\n",
       "      <td>0.218628</td>\n",
       "      <td>0.212036</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.329590</td>\n",
       "      <td>0.203003</td>\n",
       "      <td>0.298584</td>\n",
       "      <td>0.281982</td>\n",
       "      <td>0.222168</td>\n",
       "      <td>0.245239</td>\n",
       "      <td>0.238281</td>\n",
       "      <td>0.243652</td>\n",
       "      <td>0.263184</td>\n",
       "      <td>0.256592</td>\n",
       "      <td>0.232666</td>\n",
       "      <td>0.251709</td>\n",
       "      <td>0.306885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217529</td>\n",
       "      <td>0.258301</td>\n",
       "      <td>0.254150</td>\n",
       "      <td>0.301514</td>\n",
       "      <td>0.218994</td>\n",
       "      <td>0.317383</td>\n",
       "      <td>0.274902</td>\n",
       "      <td>0.208740</td>\n",
       "      <td>0.322266</td>\n",
       "      <td>0.289307</td>\n",
       "      <td>0.275879</td>\n",
       "      <td>0.326904</td>\n",
       "      <td>0.219360</td>\n",
       "      <td>0.261719</td>\n",
       "      <td>0.293213</td>\n",
       "      <td>0.237915</td>\n",
       "      <td>0.220459</td>\n",
       "      <td>0.266602</td>\n",
       "      <td>0.274658</td>\n",
       "      <td>0.255127</td>\n",
       "      <td>0.284912</td>\n",
       "      <td>0.271729</td>\n",
       "      <td>0.310059</td>\n",
       "      <td>0.375732</td>\n",
       "      <td>0.677734</td>\n",
       "      <td>0.252197</td>\n",
       "      <td>0.246704</td>\n",
       "      <td>0.236572</td>\n",
       "      <td>0.288818</td>\n",
       "      <td>0.258789</td>\n",
       "      <td>0.275635</td>\n",
       "      <td>0.318604</td>\n",
       "      <td>0.238892</td>\n",
       "      <td>0.209961</td>\n",
       "      <td>0.310547</td>\n",
       "      <td>0.261475</td>\n",
       "      <td>0.244263</td>\n",
       "      <td>0.215820</td>\n",
       "      <td>0.188843</td>\n",
       "      <td>0.265137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.454102</td>\n",
       "      <td>-1.500977</td>\n",
       "      <td>-1.343750</td>\n",
       "      <td>-1.681641</td>\n",
       "      <td>-0.941895</td>\n",
       "      <td>-1.046875</td>\n",
       "      <td>-0.886230</td>\n",
       "      <td>-0.867188</td>\n",
       "      <td>-1.428711</td>\n",
       "      <td>-1.497070</td>\n",
       "      <td>-0.862793</td>\n",
       "      <td>-1.574219</td>\n",
       "      <td>-0.854004</td>\n",
       "      <td>-0.590820</td>\n",
       "      <td>-1.564453</td>\n",
       "      <td>-1.136719</td>\n",
       "      <td>-1.098633</td>\n",
       "      <td>-1.077148</td>\n",
       "      <td>-1.237305</td>\n",
       "      <td>-0.916016</td>\n",
       "      <td>-1.345703</td>\n",
       "      <td>-1.133789</td>\n",
       "      <td>-1.242188</td>\n",
       "      <td>-0.740723</td>\n",
       "      <td>-1.365234</td>\n",
       "      <td>-0.985352</td>\n",
       "      <td>-1.442383</td>\n",
       "      <td>-1.048828</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.007812</td>\n",
       "      <td>-1.264648</td>\n",
       "      <td>-0.737793</td>\n",
       "      <td>-1.043945</td>\n",
       "      <td>-1.010742</td>\n",
       "      <td>-1.610352</td>\n",
       "      <td>-1.709961</td>\n",
       "      <td>-0.728027</td>\n",
       "      <td>-1.219727</td>\n",
       "      <td>-0.985840</td>\n",
       "      <td>-1.507812</td>\n",
       "      <td>-0.722168</td>\n",
       "      <td>-1.152344</td>\n",
       "      <td>-1.120117</td>\n",
       "      <td>-1.238281</td>\n",
       "      <td>-1.153320</td>\n",
       "      <td>-1.157227</td>\n",
       "      <td>-1.080078</td>\n",
       "      <td>-1.401367</td>\n",
       "      <td>-1.351562</td>\n",
       "      <td>-1.289062</td>\n",
       "      <td>-1.041016</td>\n",
       "      <td>-1.147461</td>\n",
       "      <td>-1.359375</td>\n",
       "      <td>-6.027344</td>\n",
       "      <td>-1.473633</td>\n",
       "      <td>-1.374023</td>\n",
       "      <td>-1.381836</td>\n",
       "      <td>-1.464844</td>\n",
       "      <td>-1.450195</td>\n",
       "      <td>-0.723633</td>\n",
       "      <td>-1.665039</td>\n",
       "      <td>-0.738281</td>\n",
       "      <td>-1.167969</td>\n",
       "      <td>-1.069336</td>\n",
       "      <td>-1.013672</td>\n",
       "      <td>-1.284180</td>\n",
       "      <td>-1.248047</td>\n",
       "      <td>-0.867188</td>\n",
       "      <td>-1.287109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.466309</td>\n",
       "      <td>-0.240479</td>\n",
       "      <td>-0.105774</td>\n",
       "      <td>-0.439941</td>\n",
       "      <td>0.169678</td>\n",
       "      <td>-0.147461</td>\n",
       "      <td>0.065308</td>\n",
       "      <td>-0.018616</td>\n",
       "      <td>-0.330078</td>\n",
       "      <td>-0.481201</td>\n",
       "      <td>-0.180054</td>\n",
       "      <td>-0.520020</td>\n",
       "      <td>0.147339</td>\n",
       "      <td>0.176147</td>\n",
       "      <td>-0.439941</td>\n",
       "      <td>0.154053</td>\n",
       "      <td>-0.203735</td>\n",
       "      <td>-0.386475</td>\n",
       "      <td>-0.283691</td>\n",
       "      <td>-0.090698</td>\n",
       "      <td>-0.489258</td>\n",
       "      <td>-0.157715</td>\n",
       "      <td>-0.232300</td>\n",
       "      <td>0.187012</td>\n",
       "      <td>0.183105</td>\n",
       "      <td>-0.225586</td>\n",
       "      <td>-0.114014</td>\n",
       "      <td>-0.290771</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135864</td>\n",
       "      <td>-0.469238</td>\n",
       "      <td>-0.108643</td>\n",
       "      <td>-0.157349</td>\n",
       "      <td>-0.172882</td>\n",
       "      <td>-0.021744</td>\n",
       "      <td>-0.408447</td>\n",
       "      <td>0.028534</td>\n",
       "      <td>-0.234375</td>\n",
       "      <td>0.030334</td>\n",
       "      <td>-0.393555</td>\n",
       "      <td>0.189453</td>\n",
       "      <td>-0.177490</td>\n",
       "      <td>0.140503</td>\n",
       "      <td>-0.566406</td>\n",
       "      <td>-0.041687</td>\n",
       "      <td>-0.337891</td>\n",
       "      <td>-0.101013</td>\n",
       "      <td>-0.437988</td>\n",
       "      <td>-0.294189</td>\n",
       "      <td>-0.165405</td>\n",
       "      <td>-0.327637</td>\n",
       "      <td>0.124298</td>\n",
       "      <td>-0.456055</td>\n",
       "      <td>-0.244263</td>\n",
       "      <td>-0.365234</td>\n",
       "      <td>-0.317383</td>\n",
       "      <td>-0.331299</td>\n",
       "      <td>-0.519531</td>\n",
       "      <td>-0.399170</td>\n",
       "      <td>0.256348</td>\n",
       "      <td>-0.617676</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>-0.361816</td>\n",
       "      <td>-0.274902</td>\n",
       "      <td>-0.237549</td>\n",
       "      <td>-0.361328</td>\n",
       "      <td>-0.489746</td>\n",
       "      <td>-0.136963</td>\n",
       "      <td>-0.345703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.262207</td>\n",
       "      <td>-0.069763</td>\n",
       "      <td>0.068909</td>\n",
       "      <td>-0.269531</td>\n",
       "      <td>0.348145</td>\n",
       "      <td>-0.004047</td>\n",
       "      <td>0.344971</td>\n",
       "      <td>0.130737</td>\n",
       "      <td>-0.148926</td>\n",
       "      <td>-0.333008</td>\n",
       "      <td>-0.047073</td>\n",
       "      <td>-0.330811</td>\n",
       "      <td>0.270996</td>\n",
       "      <td>0.305176</td>\n",
       "      <td>-0.258301</td>\n",
       "      <td>0.389160</td>\n",
       "      <td>-0.068726</td>\n",
       "      <td>-0.205933</td>\n",
       "      <td>-0.112732</td>\n",
       "      <td>0.062378</td>\n",
       "      <td>-0.329102</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>-0.074280</td>\n",
       "      <td>0.381348</td>\n",
       "      <td>0.362793</td>\n",
       "      <td>-0.073547</td>\n",
       "      <td>0.082947</td>\n",
       "      <td>-0.099976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>-0.310059</td>\n",
       "      <td>0.057449</td>\n",
       "      <td>0.034729</td>\n",
       "      <td>-0.038544</td>\n",
       "      <td>0.210449</td>\n",
       "      <td>-0.227722</td>\n",
       "      <td>0.164795</td>\n",
       "      <td>-0.038116</td>\n",
       "      <td>0.211670</td>\n",
       "      <td>-0.208252</td>\n",
       "      <td>0.442627</td>\n",
       "      <td>-0.027306</td>\n",
       "      <td>0.316650</td>\n",
       "      <td>-0.377930</td>\n",
       "      <td>0.105469</td>\n",
       "      <td>-0.203369</td>\n",
       "      <td>0.076904</td>\n",
       "      <td>-0.259521</td>\n",
       "      <td>-0.120972</td>\n",
       "      <td>0.034622</td>\n",
       "      <td>-0.151245</td>\n",
       "      <td>0.329224</td>\n",
       "      <td>-0.247253</td>\n",
       "      <td>0.136719</td>\n",
       "      <td>-0.206787</td>\n",
       "      <td>-0.146118</td>\n",
       "      <td>-0.179871</td>\n",
       "      <td>-0.337158</td>\n",
       "      <td>-0.222656</td>\n",
       "      <td>0.426758</td>\n",
       "      <td>-0.388916</td>\n",
       "      <td>0.223389</td>\n",
       "      <td>-0.236572</td>\n",
       "      <td>-0.093048</td>\n",
       "      <td>-0.073242</td>\n",
       "      <td>-0.199463</td>\n",
       "      <td>-0.358887</td>\n",
       "      <td>-0.015511</td>\n",
       "      <td>-0.164551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.058533</td>\n",
       "      <td>0.087219</td>\n",
       "      <td>0.234619</td>\n",
       "      <td>-0.104126</td>\n",
       "      <td>0.526855</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>0.593262</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>0.017109</td>\n",
       "      <td>-0.200195</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>-0.076340</td>\n",
       "      <td>0.403076</td>\n",
       "      <td>0.446777</td>\n",
       "      <td>-0.095947</td>\n",
       "      <td>0.569336</td>\n",
       "      <td>0.061584</td>\n",
       "      <td>0.036697</td>\n",
       "      <td>0.086731</td>\n",
       "      <td>0.201294</td>\n",
       "      <td>-0.178833</td>\n",
       "      <td>0.174561</td>\n",
       "      <td>0.078979</td>\n",
       "      <td>0.555664</td>\n",
       "      <td>0.516602</td>\n",
       "      <td>0.080933</td>\n",
       "      <td>0.234985</td>\n",
       "      <td>0.128784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141113</td>\n",
       "      <td>-0.133667</td>\n",
       "      <td>0.232178</td>\n",
       "      <td>0.242798</td>\n",
       "      <td>0.098633</td>\n",
       "      <td>0.374512</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.300293</td>\n",
       "      <td>0.206299</td>\n",
       "      <td>0.399902</td>\n",
       "      <td>-0.037354</td>\n",
       "      <td>0.664551</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>0.481445</td>\n",
       "      <td>-0.153687</td>\n",
       "      <td>0.262451</td>\n",
       "      <td>-0.061249</td>\n",
       "      <td>0.243286</td>\n",
       "      <td>-0.069580</td>\n",
       "      <td>0.030396</td>\n",
       "      <td>0.215332</td>\n",
       "      <td>0.047943</td>\n",
       "      <td>0.555176</td>\n",
       "      <td>0.084961</td>\n",
       "      <td>0.392822</td>\n",
       "      <td>-0.064514</td>\n",
       "      <td>0.010773</td>\n",
       "      <td>-0.043198</td>\n",
       "      <td>-0.135468</td>\n",
       "      <td>-0.056694</td>\n",
       "      <td>0.598633</td>\n",
       "      <td>-0.182861</td>\n",
       "      <td>0.382568</td>\n",
       "      <td>-0.098190</td>\n",
       "      <td>0.161987</td>\n",
       "      <td>0.110413</td>\n",
       "      <td>-0.035156</td>\n",
       "      <td>-0.214600</td>\n",
       "      <td>0.108109</td>\n",
       "      <td>0.009300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.310547</td>\n",
       "      <td>0.856934</td>\n",
       "      <td>1.087891</td>\n",
       "      <td>0.635742</td>\n",
       "      <td>1.537109</td>\n",
       "      <td>1.025391</td>\n",
       "      <td>1.694336</td>\n",
       "      <td>1.426758</td>\n",
       "      <td>1.012695</td>\n",
       "      <td>0.621094</td>\n",
       "      <td>1.123047</td>\n",
       "      <td>0.888672</td>\n",
       "      <td>1.208008</td>\n",
       "      <td>1.440430</td>\n",
       "      <td>0.866211</td>\n",
       "      <td>1.557617</td>\n",
       "      <td>0.924316</td>\n",
       "      <td>1.207031</td>\n",
       "      <td>1.234375</td>\n",
       "      <td>1.226562</td>\n",
       "      <td>0.997070</td>\n",
       "      <td>1.024414</td>\n",
       "      <td>0.839355</td>\n",
       "      <td>1.267578</td>\n",
       "      <td>1.217773</td>\n",
       "      <td>1.126953</td>\n",
       "      <td>0.930664</td>\n",
       "      <td>1.476562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.827148</td>\n",
       "      <td>0.957520</td>\n",
       "      <td>1.172852</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>0.950195</td>\n",
       "      <td>1.305664</td>\n",
       "      <td>0.797852</td>\n",
       "      <td>1.122070</td>\n",
       "      <td>1.296875</td>\n",
       "      <td>1.435547</td>\n",
       "      <td>0.822266</td>\n",
       "      <td>1.507812</td>\n",
       "      <td>0.954590</td>\n",
       "      <td>1.476562</td>\n",
       "      <td>0.985352</td>\n",
       "      <td>1.134766</td>\n",
       "      <td>0.940918</td>\n",
       "      <td>1.190430</td>\n",
       "      <td>0.892090</td>\n",
       "      <td>0.940918</td>\n",
       "      <td>1.129883</td>\n",
       "      <td>1.302734</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.287109</td>\n",
       "      <td>1.740234</td>\n",
       "      <td>0.846191</td>\n",
       "      <td>0.830566</td>\n",
       "      <td>0.722656</td>\n",
       "      <td>1.100586</td>\n",
       "      <td>0.827637</td>\n",
       "      <td>1.574219</td>\n",
       "      <td>1.018555</td>\n",
       "      <td>1.379883</td>\n",
       "      <td>0.761230</td>\n",
       "      <td>1.055664</td>\n",
       "      <td>1.135742</td>\n",
       "      <td>0.904297</td>\n",
       "      <td>0.711914</td>\n",
       "      <td>1.083008</td>\n",
       "      <td>0.954590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 780 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       contract_pct_from  contract_pct_to  ...           766           767\n",
       "count       81388.000000     81388.000000  ...  81388.000000  81388.000000\n",
       "mean           90.633275        96.474714  ...     -0.012093     -0.167358\n",
       "std            18.179258        12.141145  ...      0.188843      0.265137\n",
       "min             1.000000         1.000000  ...     -0.867188     -1.287109\n",
       "25%            80.000000       100.000000  ...     -0.136963     -0.345703\n",
       "50%           100.000000       100.000000  ...     -0.015511     -0.164551\n",
       "75%           100.000000       100.000000  ...      0.108109      0.009300\n",
       "max           100.000000       100.000000  ...      1.083008      0.954590\n",
       "\n",
       "[8 rows x 780 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of data is \", X_train_raw.shape)\n",
    "X_train_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24925,
     "status": "ok",
     "timestamp": 1577157488916,
     "user": {
      "displayName": "Badrudin Stanicki",
      "photoUrl": "",
      "userId": "13526963153831051460"
     },
     "user_tz": -60
    },
    "id": "wHW-8Ym81O0O",
    "outputId": "9b497914-7f6a-4ab5-c541-09b0975a36ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.138800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.470638e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.636027e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.523000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.655000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.168000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.880180e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  8.138800e+04\n",
       "mean   6.470638e+04\n",
       "std    6.636027e+04\n",
       "min    0.000000e+00\n",
       "25%    2.523000e+04\n",
       "50%    4.655000e+04\n",
       "75%    8.168000e+04\n",
       "max    4.880180e+06"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuYAAAEvCAYAAAAJlgSyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDDMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_raw.plot.hist(bins=50, figsize=[12,5])\n",
    "y_train_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tkCUIYpg3k4U"
   },
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3rSZf-TbcJ0z"
   },
   "source": [
    "### Build a preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TgXhDrBp7HjD"
   },
   "source": [
    "We use the column transformer from sklearn to apply different transformation on numerical and categorical features. Furthermore, some features don't have to be transformed and are just passed trough.\n",
    "\n",
    "All required steps for creating a transformer are provided in the `data_loader` file. Have a look at it and follow the individual steps. I hope you remember from the machine learning module how it works. ;)\n",
    "\n",
    "We manually add a list of strings of all the numbers from 0 to 767. These are the columns which contain a vectorised representation of the job titles. For now you don't need to understand their exact meaning and how they have been created. You are going to learn it next week. Just see them as a condensed numerical representation of the information contained in the job titles. Since these vectors are already normalised, we don't need to scale them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QnGSD6rBnavE"
   },
   "outputs": [],
   "source": [
    "data_transformer = data_loader.make_data_transformer(\n",
    "    config['features']['numerical'],\n",
    "    config['features']['categorical'],\n",
    "    config['features']['passthrough'] + [str(number) for number in range(0,768)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nchm9cQpcPyP"
   },
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ST8Vrl1QquoM"
   },
   "outputs": [],
   "source": [
    "# split data into train and validation set\n",
    "X_train_, X_val_, y_train_, y_val_ = train_test_split(\n",
    "    X_train_raw, \n",
    "    y_train_raw, \n",
    "    test_size=0.2,\n",
    "    )\n",
    "\n",
    "# apply preprocessing\n",
    "X_train = data_transformer.fit_transform(X_train_)\n",
    "X_val = data_transformer.transform(X_val_)\n",
    "X_test = data_transformer.transform(X_test_raw)\n",
    "\n",
    "# scale target varible\n",
    "y_transformer = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "# y_transformer = MinMaxScaler()\n",
    "\n",
    "y_train = y_transformer.fit_transform(y_train_)\n",
    "y_val = y_transformer.transform(y_val_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25954,
     "status": "ok",
     "timestamp": 1577157490036,
     "user": {
      "displayName": "Badrudin Stanicki",
      "photoUrl": "",
      "userId": "13526963153831051460"
     },
     "user_tz": -60
    },
    "id": "UTIwPUsIx9Kp",
    "outputId": "6994dac7-b4df-4e26-a7fa-8a4c2875274d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (65110, 1)\n",
      "Validation labels shape: (16278, 1)\n",
      "\n",
      "Training features shape: (65110, 829)\n",
      "Validation features shape: (16278, 829)\n"
     ]
    }
   ],
   "source": [
    "print('Training labels shape:', y_train.shape)\n",
    "print('Validation labels shape:', y_val.shape)\n",
    "print()\n",
    "print('Training features shape:', X_train.shape)\n",
    "print('Validation features shape:', X_val.shape)\n",
    "# print('Test features shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07a1ECRyTiSr"
   },
   "outputs": [],
   "source": [
    "# Continue on your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b-6ts1bWTh4v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97ASti5LGYOi"
   },
   "source": [
    "## Hyperparameter tuning using TensorBoard\n",
    "Let's try to optimise some hyperparameters. We are following this tutorial:\n",
    "https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8p3Tbx8cWEFA"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lEWCCQYkWIdA"
   },
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9GtR_cTTkf9G"
   },
   "source": [
    "Import TensorFlow and the TensorBoard HParams plugin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVtYvbbIWRkV"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# Continue on your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ki2O3zrPTgkU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g0QjfOYQN1DA"
   },
   "source": [
    "### Prepare for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LawexMSk5zao"
   },
   "outputs": [],
   "source": [
    "y_test_scaled = model.predict(X_test)\n",
    "y_test = y_transformer.inverse_transform(y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fyTv9MM5zHx"
   },
   "outputs": [],
   "source": [
    "df_y_test_pred = pd.DataFrame(y_test).reset_index().rename(columns={'index': 'Id', 0: 'ViewCount'})\n",
    "df_y_test_pred.to_csv('./data/jobs_10dviews_test_prediction.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pvhQjrvTB13-"
   },
   "outputs": [],
   "source": [
    "df_y_test = pd.read_csv('./data/jobs_10dviews_test.csv', header=None)\n",
    "df_y_test = df_y_test.reset_index()\n",
    "df_y_test = df_y_test.rename(columns={'index': 'Id', 0: 'Expected'})\n",
    "df_y_test.to_csv('./data/jobs_10dviews_test_expected.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Day1&2_feed_forward_NN_regression_helper.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
