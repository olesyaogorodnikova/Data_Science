---
title: "Excer_2"
output: html_document
---

```{r 

```
```{r}
rnorm(9,90,36)
print(k)
k=replicate(10,rnorm(10000,90,12))
df =data.frame(k)
me=apply(df,2,mean, na.rm=TRUE)
me
hist(me)

```
```{r}
pop_mean = 90
pop_std = 36
sample_size = 9

std_sampling_distr_of_the_mean = pop_std/sqrt(sample_size)

sample <- data.frame("sample" = rnorm(100000, 90, std_sampling_distr_of_the_mean))
print(sample)
mean(sample$sample)

ggplot(sample, aes(x = sample)) + 
  geom_histogram(aes( y = ..density.. ), fill = "red", color = "blue") +
  labs(title = "Sampling distribution of the mean", x = "x", y = "y") + 
  labs(title = "Normal Distributions", x = "x", y = "y")
```


```{r}
k=replicate(1000,rnorm(10,90,12))

x <- seq(1000)
for (i in 1:length(k[1,])){
   x[i] <- mean(k[,i])
}
hist(x)
dx
dx<-data.frame(x)
ggplot(dx, aes(x)) + 
  geom_histogram(aes( y = ..density.. ), fill = "red", color = "blue") +
  labs(title = "Sampling distribution of the mean", x = "x", y = "y") + 
  labs(title = "Normal Distributions", x = "x", y = "y")

```
```{r}
n <- 1000
x <- seq()
for (i in 1:n) {
   s <- data.frame("sample" = rnorm(10, 90, 12))
   x[i] <- mean(s$sample)
}
hist(x)
```


```{r}
x =replicate(1000,mean(data.frame("sample" = rnorm(10, 90, 12))$sample))
hist(x)

sample <- data.frame("sample" = rnorm(10000, 90, 12))
mean(sample$sample)
sample

hist(unlist(sample$sample))
```

a. When the margin of error is small, the confidence level is high.
b. The 95% CI is wider than the 99% CI (given all the rest the same).
c. When the margin of error is large, the confidence interval is large (wide).
d. If the sample size increases, the CI becomes wider.
e. A confidence interval is a point estimator.
f. A sample mean is an example of a point estimate.

```{r}
#a) false
#b) false
#c) true
#d) no
#e) no
#f) yes

```

A population is known to be normally distributed.

Compute the 95% confidence interval on the mean based on the following sample of nine: 8, 9, 10, 13, 14, 16, 17, 20, 21.

Now compute the 99% confidence interval using the same data.

```{r}
sample <- c(8, 9, 10, 13, 14, 16, 17, 20, 21)
#CI(sample, ci=0.95)
a=mean(sample)
s=sd(sample)

error <- qnorm(0.975)*s/sqrt(9)
left <- a-error
left
right <- a+error
right


error <- qnorm(0.995)*s/sqrt(9)
left <- a-error
left
right <- a+error
right

```

Exercise 4: CLT and LLN
Generate sample means x̄ for 50 samples of 100 numbers randomly spread between 0 and 1. The sampling distribution of x̄ is the distribution of the means from all possible samples.

Make a histogram of the all 50 sample means.

Give the Law of Large Numbers and the Central Limit Theorem in context of this exercise.

Compute the mean and median. Use the information and the histogram in (a). Does the distribution appear to be roughly normal, as the CLT states.

```{r}

set.seed(100)

sample(seq(0, 1,0.01), 50)
sample
c<-replicate(50,mean(runif(100, min = 0, max = 1)))
hist(c)
mean(c)
median(c)
a=runif(100)
```

Exercise 5: Central Limit Theorem
Consider taking random samples of various sizes n from an exponential distribution. At what sample size n does the normal distribution make a good approximation to the actual distribution of the sample mean?


```{r}
n <- 10
lambda <- 0.2
pop_mean <- 1 / lambda
pop_sd <- 1 / lambda
pop_var <- pop_sd ^ 2
sim<-100

E <- matrix(rexp(sim*n,lambda),sim,n)
means.exp = apply(E, 1, mean)
hist(means.exp)
hist(E)
```


```{r}

library(ggplot2)


set.seed(42)

# Number of samples and lambda value that are going to be drawn from the exponential distribution
n <- 40
lambda <- 0.2

# Draw randomly from the exponential distribution, compute mean and do so 10000 times

sample_means <- replicate(100000, mean(rexp(n, lambda)))
sample_means
hist(replicate(100,mean(rexp(n, lambda))))
# Create dataframe from sample means

sample_means_df <- data.frame(sample_means)
sample_means_df

# Compute means for graphical comparison

theoretical_mean <- 1/lambda
theoretical_mean
sample_mean <- mean(sample_means_df$sample_means)
sample_mean

# Create plot

plot <- ggplot(sample_means_df, aes(x = sample_means)) +
  geom_histogram(binwidth = lambda,
                 fill = "grey", color = "black",
                 aes(y = ..density..)) +
  geom_vline(xintercept = theoretical_mean, size = 1.0, color = "black") +
  geom_vline(xintercept = sample_mean, size = 1.0, color = "white", linetype = "longdash") +
  scale_x_continuous(name = "Means", breaks = seq(1, 8, lambda*2)) +
  ggtitle("Density of 40 Averages of the Exponential Distribution") + 
  ylab("Density") +
  theme(plot.title = element_text(lineheight = 0.8, face = "bold"))

plot
```


```{r}
exp_rand = replicate(10, rexp(10, 3))
exp_rand
hist(exp_rand)
ex_list = split(exp_rand, rep(1:ncol(exp_rand), each = nrow(exp_rand)))
class(ex_list)
exp2 <- c()
for (i in ex_list) {
  ex <- mean(i)
  exp2 <- c(exp2,ex)
}
exp2
hist(exp2)

```

Exercise 6: Bootstrapping
Take the sample: 8, 12, 58, 94, 103, 115, drawn from a population with unknown distribution
Re-sample with replacement 100 times with sample(x, size, replace=TRUE).
Compute a vector with the means for each re-sample.
Plot their sample means.
Calculate a 95% confidence interval for the mean of this population.

```{r}

x<- c(8, 12, 58, 94, 103, 115)
m<- replicate(100, mean(sample(x, 6, replace=TRUE)))
m_df <-data.frame("means"=m)
m_df

ggplot(m_df, aes(x=means)) + geom_histogram(aes(y = ..density..), fill = "grey", color = "black") +
  ylab("Density") +
  theme(strip.text.x = element_text(size = 12),
        axis.title.x = element_text(size = 12),
        axis.text.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        axis.text.y = element_text(size = 12))

ci<-quantile(m_df$means,c(0.025, 0.975))
ci

samples_df <- mutate(m_df, CI = means > ci[1] & means < ci[2])
samples_df

ggplot(samples_df, aes(x = means)) +
  geom_histogram(aes(y = ..density..), fill = "grey", color = "black") +
  geom_vline(xintercept = ci[1]) +
  geom_vline(xintercept = ci[2]) +
  geom_area(stat = "function", fun = dnorm, 
            args = list(mean = mean(samples_df$means), sd = sd(samples_df$means)), 
            fill = "red", xlim = ci, alpha = 0.5) +
  geom_area(stat = "function", fun = dnorm, 
            args = list(mean = mean(samples_df$means), sd = sd(samples_df$means)), 
            fill = "blue", xlim = c(min(samples_df$means), ci[1]), alpha = 0.5) +
  geom_area(stat = "function", fun = dnorm, 
            args = list(mean = mean(samples_df$means), sd = sd(samples_df$means)), 
            fill = "blue", xlim = c(ci[2], max(samples_df$means)), alpha = 0.5) +
  ylab("Density") +

  theme(axis.title.x = element_text(size = 12),
        axis.text.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        axis.text.y = element_text(size = 12))



meanv <- rep(0, 100)
for(i in 1:length(m[1,])){
      meanv[i] <- mean(m[,i])
}
plot(meanv)
hist(meanv)
s=sd(meanv)
error <- qnorm(0.975)*s/sqrt(6)
left <- quantile(meanv, c(0.975))
left
right <- quantile(meanv, c(0.025))
right



```


Exercise 7: Bootstrapping
The process above can be extended to other statistics besides the mean. Using your own data set (from your project, or one we used yesterday) try to implement a bootstrapping approach following along in this tutorial: http://www.stat.wisc.edu/~larget/stat302/chap3.pdf.
Find the population mean and 95% CI of one variable in your data. How do you interpret the 95% CI values?
Approximate the population statistics by extending this approach also to other sample statistics.
Calculate the 95% CI of the difference in means between two groups in your data (e.g. difference in average rating for role-playing games and puzzle games).

```{r}
data2 <- read.csv("Employee.Compensation_.csv")
data2
str(data2$Salaries) 
sal = data2$Salaries

sal.mean = mean(sal)
sal.mean

B = 1000

boot.samples = matrix(sample(sal, size = B * n, replace = TRUE),
B, n)


```


```{r}
library(dplyr)


df <- read.csv("baseball_.csv")
head(df)
# Part 1

# Sample nrow(df) times from the home run column of the baseball dataset and compute mean
# at each iteration
df$hr


samples <- replicate(nrow(df), mean(sample(df$hr, size = nrow(df), replace = TRUE)))
samples_df <- data.frame("Means" = samples)

# Compute 95% confidence interval

CI <- quantile(samples_df$Means, c(0.025, 0.975))
CI

p_1 <- ggplot(samples_df, aes(x = Means)) +
  geom_histogram(aes(y = ..density..), fill = "grey", color = "black") +
  geom_vline(xintercept = CI[1]) +
  geom_vline(xintercept = CI[2]) +
  geom_area(stat = "function", fun = dnorm, 
            args = list(mean = mean(samples_df$Means), sd = sd(samples_df$Means)), 
            fill = "red", xlim = CI, alpha = 0.5) +
  geom_area(stat = "function", fun = dnorm, 
            args = list(mean = mean(samples_df$Means), sd = sd(samples_df$Means)), 
            fill = "blue", xlim = c(min(samples_df$Means), CI[1]), alpha = 0.5) +
  geom_area(stat = "function", fun = dnorm, 
            args = list(mean = mean(samples_df$Means), sd = sd(samples_df$Means)), 
            fill = "blue", xlim = c(CI[2], max(samples_df$Means)), alpha = 0.5) +
  ggtitle("Averages of Homeruns 1871-2007") +
  ylab("Density") +
  theme(title = element_text(size = 14),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 12))

p_1

# Part 2: Is there a difference in means between homeruns in the 1980s and 1990s (two groups of data)

# Subset data

hrs80 <- filter(df, year %in% c(1980:1989))
hrs90 <- filter(df, year %in% c(1990:1999))

# Sample nrow(df) times from the home run column of the 80's and 90's subsets and compute mean
# at each iteration

samples_80s <- replicate(length(hrs80$hr), mean(sample(hrs80$hr, size = length(hrs80$hr), replace = TRUE)))
samples_90s <- replicate(length(hrs80$hr), mean(sample(hrs90$hr, size = length(hrs80$hr), replace = TRUE)))

# Make dataframe

grpsamples_df <- data.frame("Means" = c(samples_80s, samples_90s),
                            "Decade" = c(rep("1980's", length(samples_80s)),
                                         rep("1990's", length(samples_90s))))

# Create Boxplot

p_2 <- ggplot(grpsamples_df, aes(x = Decade, y = Means)) +
  geom_boxplot(outlier.colour="red") +
  theme(title = element_text(size = 14),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 12))

p_2

# In the boxplot there is an observable difference in means. Let us now bootstrap the differences
# in means and calculate the 95% confidence interval.

mean_diffs <- replicate(1000, mean(sample(samples_80s - samples_90s, replace = TRUE)))

quantile(mean_diffs, probs = c(0.025, 0.975))

```


```{r}
samples = replicate(1000, rnorm(9, 90, 36))
class(samples)
sample_list = split(samples, rep(1:ncol(samples), each = nrow(samples)))
class(sample_list)
b2 <- c()
for (i in sample_list) {
   b <- mean(i)
   b2 <- c(b2,b)
}
```


```{r}
k <- replicate(10,rnorm(9,90,36))

m <- matrix(0, nrow=10, ncol=10)

for (i in 1:length(k[1,])){

  m[,i] <- unlist(c(k[,i], mean(k[,i])))

}


hist(m)
```


```{r}
library(boot)
hsb2 <- read.table("https://stats.idre.ucla.edu/stat/data/hsb2.csv", sep=",", header=T)

fc <- function(d, i){
	d2 <- d[i,]                      # i-oviy ryad
	return(cor(d2$write, d2$math))   # korrelaciya writw and math
}

set.seed(626)
results <- boot(hsb2, fc, R=500)     # boot(data = hsb2, statistic = fc, R = 500)
results

# get 95% confidence interval 
boot.ci(results, type="bca")



```


```{r}
```


```{r}
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
